{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this naive test approach we are:\n",
    "- Representing all words as vectors for keywords and categories. \n",
    "- Summarizing words vectors for each category\n",
    "- Summarizing words vectors for all keywords over the channel(I should note that simply summarizing looks like not the best choice, I will investigate and tests this part later)\n",
    "- Searching for k-nearest neighbors using the cosine distance. (For tests we are using NearestNeighbors brute force algorithm, it should be changed to Local Sensitivity Hashing NearestNeighbors clustering that is the best choice for this task in the terms of performance).\n",
    "\n",
    "Let's define the simple class that will do such classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import spacy\n",
    "\n",
    "\n",
    "class KeywordsClassifier(object):\n",
    "\n",
    "    def __init__(self, nearestNeighborsLearner, categories, topN):\n",
    "        self.nearestNeighborsLearner = nearestNeighborsLearner \n",
    "        self.categories = categories \n",
    "        self.topN = topN \n",
    "\n",
    "    @classmethod\n",
    "    def CreateKeywordsClassifier(cls, nlp, categories, topNCount):\n",
    "        '''\n",
    "        @param nlp: spacy dictinary \n",
    "        @param categories: list of categories\n",
    "        @param topNCount: number of categories to chose\n",
    "        @return: instance of KeywordsClassifier class\n",
    "        '''\n",
    "        catDic = KeywordsClassifier.GetVerticalsVectorsDict(nlp, categories)\n",
    "        catArray = numpy.array(list(catDic.values()))\n",
    "        nn = NearestNeighbors(topNCount, algorithm='brute', metric='cosine') #for production we should use LSHForest instead\n",
    "        nn.fit(catArray)\n",
    "        return KeywordsClassifier(nn, list(catDic.keys()), topNCount)\n",
    "\n",
    "    @staticmethod\n",
    "    def GetVerticalsVectorsDict(nlp, verticals):\n",
    "        verticalsDict = {}\n",
    "\n",
    "        for category in verticals:\n",
    "            text = nlp(category.replace(\"&\", \"\"))\n",
    "            verticalsDict[category] = text.vector\n",
    "\n",
    "        return verticalsDict\n",
    "\n",
    "\n",
    "    def ClassifyKeywords(self, keywordsVector):\n",
    "        '''\n",
    "        @param keywordsVector: resulting keywords vector\n",
    "        @return: ordered list of tuples representing of top N categories names with cosine similarities\n",
    "        '''\n",
    "        result = []\n",
    "        distances, indices = self.nearestNeighborsLearner.kneighbors(keywordsVector.reshape(1, -1))\n",
    "        curIter = 0\n",
    "\n",
    "        for curIndex in numpy.nditer(indices):\n",
    "            category = self.categories[curIndex]\n",
    "            cosDistance = distances[0][curIter]\n",
    "            cosineSim = 1 - cosDistance\n",
    "            tuple = (category, cosineSim)\n",
    "            result.append(tuple)\n",
    "            curIter += 1\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can start we need to load the spacy dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 'nlp' not in globals(): # to avoid loading huge spacy dictionary several times\n",
    "    print(\"Loading dictinary...\")\n",
    "    nlp = spacy.load('en')\n",
    "    print(\"Dictinary loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple help function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ClassifyIt(categories, keywords, topN):\n",
    "    '''\n",
    "        @param categories: list of categories\n",
    "        @param keywords: a single string that contains keywords\n",
    "        @param topNCount: number of categories to choose\n",
    "    '''\n",
    "    keywordsVect = nlp(keywords).vector\n",
    "    classifier = KeywordsClassifier.CreateKeywordsClassifier(nlp, categories, topN)\n",
    "    results = classifier.ClassifyKeywords(keywordsVect)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can play with some toy-examples and see the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cars', 0.62240266799926758)]\n"
     ]
    }
   ],
   "source": [
    "categories = { 'fruits', 'cars', 'motorcycles', 'animals', 'people', 'politics', 'design'}\n",
    "keywords = 'BMW, repair, NISSAN, wheel, TOYOTA, road signs'\n",
    "topN = 1 #count of categories to chose\n",
    "\n",
    "ClassifyIt(categories, keywords, topN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer is correct - cars. Note that we have two similar categories - motorcycles and cars(some of the brands from categories above are producing both cars and motorcycles), but that was not a problem. Let change the keywords a little if what were keywords from motorcycles group to answer the question: will we able to classify it still correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('motorcycles', 0.57702171802520752)]\n"
     ]
    }
   ],
   "source": [
    "keywords = 'BMW, SUZUKI, Gixer, Harley-Davidson, road signs'\n",
    "ClassifyIt(categories, keywords, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct. \n",
    "Lets try mixed classification:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cars', 0.53120368719100952), ('fruits', 0.41091710329055786)]\n"
     ]
    }
   ],
   "source": [
    "keywords = 'BMW, cherry, NISSAN, banana, TOYOTA, apple, road signs'\n",
    "topN = 2 #count of categories to chose\n",
    "ClassifyIt(categories, keywords, topN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now some real, problematic example - MLB channel https://www.youtube.com/user/MLB/ the largest youtube channel in our database: more than 3M of keywords. As categories, we will use verticals from Google AdWords and as keywords - tags of all videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('American Football', 0.77245274247048656), ('American Football Equipment', 0.74987778186729015), ('Chicago', 0.72816600489182681), ('Baseball', 0.7276862459056388)]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "def GetLargestKeywordsDb():\n",
    "    sumVector = numpy.zeros(nlp.vocab.vectors_length)\n",
    "\n",
    "    keywords = []\n",
    "    print(\"Loading keywords...\")\n",
    "    with open('235227_keywords.csv', 'rt') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        for row in reader:\n",
    "            keywords.append(row[0])\n",
    "\n",
    "    print(\"Calculating vectors sum...\")\n",
    "    counterDict = Counter(keywords) #optimization for keywords duplicates\n",
    "    for word, repCount in counterDict.items():  # summarizing words vectors\n",
    "        curVect = nlp(word).vector\n",
    "        sumVector += (curVect * repCount)\n",
    "\n",
    "    return sumVector\n",
    "\n",
    "def GetVerticalsListFromFile():\n",
    "    verticals = []\n",
    "    with open('verticals.csv', 'rt') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        next(reader, None)  # skip the headers\n",
    "        for row in reader:\n",
    "            verticals.append(row[0].replace(\"&\", \"\"))\n",
    "    return verticals\n",
    "\n",
    "if 'keywordsVectL' not in globals(): \n",
    "    keywordsVectL = GetLargestKeywordsDb()\n",
    "\n",
    "categoriesL = GetVerticalsListFromFile()\n",
    "    \n",
    "classifier = KeywordsClassifier.CreateKeywordsClassifier(nlp, categoriesL, 4)\n",
    "results = classifier.ClassifyKeywords(keywordsVectL)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the correct answer is in the 4th place. There can be several reason for that and this should be investigated additionally.\n",
    "\n",
    "For some channels that I have tested, this classification approach works, generally, correctly, for some - not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
